# PS-VAE Default Configuration
# Paper: "Both Semantics and Reconstruction Matter"

# Model Configuration
model:
  # Representation encoder settings
  encoder:
    type: "dinov2"  # Options: dinov2, siglip, clip
    size: "large"   # Options: base, large, giant
    freeze: false   # Freeze for S-VAE, unfreeze for PS-VAE
  
  # Latent space settings (as per paper)
  latent:
    dim: 96                    # 96 channels as per paper
    spatial_downsample: 16     # 16x16 spatial downsampling
  
  # Loss weights
  loss:
    kl_weight: 0.0001          # KL divergence weight
    semantic_weight: 1.0       # Semantic reconstruction weight
    pixel_weight: 1.0          # Pixel reconstruction weight
    perceptual_weight: 0.1     # LPIPS perceptual loss weight

# Diffusion Configuration
diffusion:
  num_timesteps: 1000
  beta_schedule: "scaled_linear"
  beta_start: 0.0001
  beta_end: 0.02
  prediction_type: "epsilon"   # Options: epsilon, v_prediction
  
  # DiT settings
  dit:
    hidden_size: 1152
    depth: 28
    num_heads: 16
    mlp_ratio: 4.0
    text_dim: 4096             # T5-XXL dimension
    num_text_tokens: 77
    class_dropout_prob: 0.1
    learn_sigma: true

# Training Configuration
training:
  # Basic settings
  seed: 42
  epochs: 100
  batch_size: 32
  gradient_accumulation_steps: 1
  
  # Optimizer
  optimizer:
    type: "adamw"
    lr: 1.0e-4
    weight_decay: 0.01
    betas: [0.9, 0.999]
    eps: 1.0e-8
  
  # Learning rate scheduler
  scheduler:
    type: "cosine"
    warmup_steps: 5000
    min_lr: 1.0e-6
  
  # Mixed precision
  mixed_precision: "bf16"      # Options: no, fp16, bf16
  
  # Checkpointing
  save_every: 5000
  eval_every: 1000
  
  # EMA
  ema:
    enabled: true
    decay: 0.9999
    update_every: 10

# Data Configuration
data:
  image_size: 256
  train_data_dir: "data/train"
  val_data_dir: "data/val"
  num_workers: 8
  
  # Augmentation
  augmentation:
    random_flip: true
    random_crop: true
    color_jitter: false

# Logging Configuration
logging:
  project_name: "ps-vae"
  run_name: null               # Auto-generated if null
  log_every: 100
  use_wandb: true

# Inference Configuration
inference:
  num_inference_steps: 50
  cfg_scale: 7.5
  eta: 0.0                     # DDIM eta (0 = deterministic)

